{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[DIY Covid-19 Dashboard Kit](https://github.com/fsmeraldi/diy-covid19dash) (C) Fabrizio Smeraldi, 2020 ([f.smeraldi@qmul.ac.uk](mailto:f.smeraldi@qmul.ac.uk) - [web](http://www.eecs.qmul.ac.uk/~fabri/)). All rights reserved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DIY Covid-19 Dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a template for your DIY Covid Dashboard, to which you can add the code you developed in the previous notebooks. The dashboard will be displayed using [voila](https://voila.readthedocs.io/en/stable/index.html), a Python dashboarding tool that converts notebooks to standalone dashboards. Contrary to the other libraries we have seen, the ```voila``` package must be installed using *pip* or *conda* but it does not need to be imported - it rather acts at the level of the notebook server. Package ```voila``` is already installed on the EECS JupyterHub as well as in the binder - to install it locally, follow the [instructions](https://voila.readthedocs.io/en/stable/install.html) online.\n",
    "\n",
    "Broadly speaking, Voila acts by **running all the cells in your notebook** when the dashboard is first loaded; it then hides all code cells and displays all markdown cells and any outputs, including widgets. However, the code is still there in the background and handles any interaction with the widgets. To view this dashboard template rendered in Voila click [here](https://mybinder.org/v2/gh/fsmeraldi/diy-covid19dash/main?urlpath=%2Fvoila%2Frender%2FDashboard.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import ipywidgets as wdg\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from uk_covid19 import Cov19API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# make figures larger\n",
    "plt.rcParams['figure.dpi'] = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load initial data from disk\n",
    "\n",
    "You should include \"canned\" data in ```.json``` files along with your dashboard. When the dashboard starts, it should load that data (the code below will be hidden when the dashboard is rendered by Voila)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load JSON files and store the raw data in some variable. Edit as appropriate\n",
    "jsondata={}\n",
    "\n",
    "### pcr_comp json load ###\n",
    "\n",
    "with open(\"pcr_comp.json\", \"rt\") as INFILE:\n",
    "    pcr_data = json.load(INFILE)\n",
    "\n",
    "### vax_occ json load ###\n",
    "\n",
    "with open(\"sick_vax.json\", \"rt\") as INFILE:\n",
    "    sick_vax_data = json.load(INFILE)\n",
    "\n",
    "### cas_nation json load ###\n",
    "\n",
    "with open(\"cas_nation_data.json\", \"rt\") as INFILE:\n",
    "    cas_nat_data = json.load(INFILE)\n",
    "\n",
    "\n",
    "### death_gender_age load ###\n",
    "\n",
    "with open(\"death_data.json\", \"rt\") as INFILE:\n",
    "    death_data = json.load(INFILE)\n",
    "\n",
    "with open(\"sex_data.json\", \"rt\") as INFILE:\n",
    "    sex_data = json.load(INFILE)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrangle the data\n",
    "\n",
    "The dashboard should contain the logic to wrangle the raw data into a ```DataFrame``` (or more than one, as required) that will be used for plotting. The wrangling code should be put into a function and called on the data from the JSON file (we'll need to call it again on any data downloaded from the API).  In this template, we just pretend we are wrangling ```rawdata``` and generate a dataframe with some random data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           England Scotland Wales Northern Ireland\n",
      "2020-01-31     NaN      NaN   NaN              NaN\n",
      "2020-02-01     NaN      NaN   NaN              NaN\n",
      "2020-02-02     NaN      NaN   NaN              NaN\n",
      "2020-02-03     NaN      NaN   NaN              NaN\n",
      "2020-02-04     NaN      NaN   NaN              NaN\n",
      "...            ...      ...   ...              ...\n",
      "2022-11-20     NaN      NaN   NaN              NaN\n",
      "2022-11-21     NaN      NaN   NaN              NaN\n",
      "2022-11-22     NaN      NaN   NaN              NaN\n",
      "2022-11-23     NaN      NaN   NaN              NaN\n",
      "2022-11-24     NaN      NaN   NaN              NaN\n",
      "\n",
      "[1029 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def wrangle_data(rawdata):\n",
    "    \"\"\" Parameters: rawdata - data from json file or API call. Returns a dataframe.\n",
    "    Edit to include the code that wrangles the data, creates the dataframe and fills it in. \"\"\"\n",
    "    df=pd.DataFrame(index=range(0,100), columns=['One', 'Two'])\n",
    "    # we have no real data to wrangle, so we just generate two random walks.\n",
    "    one=two=0.0\n",
    "    for i in range(0,100):\n",
    "        df.loc[i,'One']=one\n",
    "        df.loc[i,'Two']=two\n",
    "        one+=np.random.randn()\n",
    "        two+=2*np.random.randn()\n",
    "    return df\n",
    "\n",
    "# putting the wrangling code into a function allows you to call it again after refreshing the data through \n",
    "# the API. You should call the function directly on the JSON data when the dashboard starts, by including \n",
    "# the call in the cell as below:\n",
    "df=wrangle_data(jsondata) # df is the dataframe for plotting\n",
    "\n",
    "### Pre-requisite Functions ###\n",
    "\n",
    "#function to get the panda of a datestring\n",
    "\n",
    "def parse_date(datestring):\n",
    "    \"\"\" Convert a date string into a pandas datetime object \"\"\"\n",
    "    return pd.to_datetime(datestring, format=\"%Y-%m-%d\")\n",
    "\n",
    "\n",
    "### Wrangling the Data via Functions for each Graph ###\n",
    "\n",
    "### pcr_comp Data Wrangling ###\n",
    "\n",
    "def pcr_comp_wrangle(rawdata):\n",
    "    pcr_comp_data = rawdata['data']\n",
    "    \n",
    "    pcr_dates = [dic[\"date\"] for dic in pcr_comp_data] # getting the dates\n",
    "    pcr_dates.sort()    # sorting the dates\n",
    "\n",
    "     \n",
    "    pcr_startdate = parse_date(pcr_dates[0])    # getting the startdate\n",
    "    pcr_enddate = parse_date(pcr_dates[-1])     # getting the endddate\n",
    "\n",
    "    pcr_index = pd.date_range(pcr_startdate, pcr_enddate, freq='D')     # getting the index for the dataframe\n",
    "\n",
    "\n",
    "    pcr_comp_df = pd.DataFrame(index=pcr_index, columns=[\"newPCR\", \"plannedPCR\"])   # creating the dataframe\n",
    "\n",
    "    # filling the the dataframe\n",
    "\n",
    "    for entry in pcr_comp_data:\n",
    "\n",
    "        date = parse_date(entry[\"date\"])\n",
    "\n",
    "        for column in [\"newPCR\", \"plannedPCR\"]:     # learning: make sure you have the same column name for the data frame and the list / json file\n",
    "\n",
    "         if pd.isna(pcr_comp_df.loc[date, column]):\n",
    "\n",
    "            value = float(entry[column]) if entry[column] !=None else 0.0\n",
    "\n",
    "            pcr_comp_df.loc[date, column] = value\n",
    "\n",
    "    pcr_comp_df.fillna(0.0, inplace=True)   \n",
    "    return pcr_comp_df\n",
    "\n",
    "\n",
    "pcr_comp_df = pcr_comp_wrangle(pcr_data) # mangling the data initally when loading \n",
    "\n",
    "\n",
    "###\n",
    "\n",
    "\n",
    "### vax_occ Data Wrangling ###\n",
    "\n",
    "def vax_occ_wrangle(rawdata):\n",
    "\n",
    "    sick_vax_data = rawdata['data']\n",
    "    #sick_vax_datalist = sick_vax_data[\"data\"]   # getting the data list\n",
    "\n",
    "\n",
    "    sick_vax_dates = [dictionary[\"date\"] for dictionary in sick_vax_data ]       # getting start and end dates\n",
    "    sick_vax_dates.sort()\n",
    "\n",
    "    sick_vax_startdate = parse_date(sick_vax_dates[0])  \n",
    "    sick_vax_enddate = parse_date(sick_vax_dates[-1])\n",
    "\n",
    "    sick_vax_index = pd.date_range(sick_vax_startdate, sick_vax_enddate, freq='D')      # creating the index based on dates\n",
    "\n",
    "    sick_vax_df = pd.DataFrame(index=sick_vax_index, columns=[\"cumAdmin\", \"occMVBeds\", \"cumVax1\", \"cumVax2\", \"cumVax3\"])    # creating the data frame\n",
    "\n",
    "    #   fillinf the data frame\n",
    "\n",
    "    for entry in sick_vax_data:\n",
    "\n",
    "     date = parse_date(entry[\"date\"])\n",
    "\n",
    "     for column in [\"cumAdmin\", \"occMVBeds\", \"cumVax1\", \"cumVax2\", \"cumVax3\"]: \n",
    "\n",
    "            if pd.isna(sick_vax_df.loc[date, column]):\n",
    "\n",
    "              value = float(entry[column]) if entry[column] !=None else 0.0\n",
    "\n",
    "              sick_vax_df.loc[date, column] = value\n",
    "\n",
    "    sick_vax_df.fillna(0.0, inplace=True)\n",
    "    return sick_vax_df\n",
    "\n",
    "sick_vax_df = vax_occ_wrangle(sick_vax_data)    # mangling the data initially when loading\n",
    "\n",
    "### \n",
    "\n",
    "\n",
    "\n",
    "### cas_nation Data Wrangling ###\n",
    "\n",
    "def cas_nation_wrangle(rawdata):\n",
    "\n",
    "    new_case_nat_data = []                          # here we are getting a list of api data structures. We are iterating over them them to get the data list and in paralell combining that data into one variable\n",
    "    for data in rawdata:\n",
    "        new_case_nat_data += data['data']\n",
    "\n",
    "    cas_nat_data = new_case_nat_data \n",
    "\n",
    "    #cas_nat_data = rawdata\n",
    "    cas_nat_dates_raw=[dictionary['date'] for dictionary in cas_nat_data ]\n",
    "    cas_nat_dates_raw.sort()\n",
    "\n",
    "\n",
    "    cas_nat_dates_dic = {date for date in cas_nat_dates_raw} # removing duplicates by transforming into a dictionary and back into a sorted list\n",
    "    cas_nat_dates = list(cas_nat_dates_dic)\n",
    "    cas_nat_dates.sort()    # sorting the dates (not required but I wanted the data clean)\n",
    "\n",
    "    cas_nat_startdate=parse_date(cas_nat_dates[0])  # getting the start and end dates\n",
    "    cas_nat_enddate=parse_date(cas_nat_dates[-1])\n",
    "\n",
    "    #cas_nat_index_m=pd.date_range(cas_nat_startdate, cas_nat_enddate, freq='M') # creating the index for the dataframe with monthly frequency (do i need this? currently not returned)\n",
    "    cas_nat_index_d=pd.date_range(cas_nat_startdate, cas_nat_enddate, freq='D') # creating the index for the dataframe with daily frequency\n",
    "\n",
    "    cas_nat_df_d = pd.DataFrame(index=cas_nat_index_d, columns = (\"England\", \"Scotland\", \"Wales\", \"Northern Ireland\"))\n",
    "    print(cas_nat_df_d) # building a dataframe based on daily frequency\n",
    "\n",
    "    #cas_nat_df_m = pd.DataFrame(index=cas_nat_index_m, columns = (\"England\", \"Scotland\", \"Wales\", \"Northern Ireland\"))\n",
    "    #print(cas_nat_df_m) # building a dataframe based on monthly frequency\n",
    "\n",
    "    # filling the dataframes by iterating over the data and having conditional löogic based on the Area Name and Date columns\n",
    "\n",
    "    for dictionary in cas_nat_data:\n",
    "        date=parse_date(dictionary['date'])\n",
    "\n",
    "        if dictionary['areaName'] == \"England\":\n",
    "\n",
    "            value= float(dictionary['newCases']) if dictionary['newCases']!=None else 0.0\n",
    "\n",
    "            cas_nat_df_d.loc[date, \"England\"]= value\n",
    "\n",
    "        if dictionary['areaName'] == \"Scotland\":\n",
    "\n",
    "            value= float(dictionary['newCases']) if dictionary['newCases']!=None else 0.0\n",
    "\n",
    "            cas_nat_df_d.loc[date, \"Scotland\"]= value\n",
    "\n",
    "\n",
    "        if dictionary['areaName'] == \"Wales\":\n",
    "\n",
    "            value= float(dictionary['newCases']) if dictionary['newCases']!=None else 0.0\n",
    "\n",
    "            cas_nat_df_d.loc[date, \"Wales\"]= value\n",
    "\n",
    "        if dictionary['areaName'] == \"Northern Ireland\":\n",
    "\n",
    "            value= float(dictionary['newCases']) if dictionary['newCases']!=None else 0.0\n",
    "\n",
    "            cas_nat_df_d.loc[date, \"Northern Ireland\"]= value\n",
    "\n",
    "        cas_nat_df_d.fillna(0.0, inplace=True)  # filling the dataframe with 0.0 for missing values\n",
    "\n",
    "    return cas_nat_df_d\n",
    "\n",
    "cas_nat_df_d = cas_nation_wrangle(cas_nat_data) # mangling the data initially when loading\n",
    "\n",
    "###\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### death_gender_age load ###\n",
    "\n",
    "def death_gender_wrangle(rawdata_death, rawdata_sex):\n",
    "\n",
    "    death_data = rawdata_death['data']\n",
    "    sex_data = rawdata_sex['data']\n",
    "\n",
    "\n",
    "    # getting the timeseries\n",
    "\n",
    "\n",
    "    death_dates_raw =[dictionary['date'] for dictionary in death_data ]\n",
    "\n",
    "    death_dates_dic = {date for date in death_dates_raw} # removing duplicates by transforming into a dictionary and back into a sorted list \n",
    "    death_dates = list(death_dates_dic)\n",
    "    death_dates.sort()\n",
    "\n",
    "    # gettingn start and end dates\n",
    "\n",
    "    death_startdate=parse_date(death_dates[0])\n",
    "    death_enddate=parse_date(death_dates[-1])\n",
    "\n",
    "    death_index_d=pd.date_range(death_startdate, death_enddate, freq='D') # creating the index for the dataframe with daily frequency\n",
    "\n",
    "    # getting female / male cases and the age ranges / is this needed ???\n",
    "\n",
    "    female_cases = [dictionary['femaleCases'] for dictionary in sex_data]\n",
    "    male_cases = [dictionary['maleCases'] for dictionary in sex_data]\n",
    "\n",
    "    age_bands =[]\n",
    "    for item in male_cases:\n",
    "        age_bands += [dictionary['age'] for dictionary in item]\n",
    "\n",
    "    age_bands = list(set(age_bands)) # removing duplicates and sorting (how did sorting here actually happen? Im not sure. But it sorted for all but one age band so Im doing it fully correct below)\n",
    "    age_bands.sort()\n",
    "\n",
    "\n",
    "    def min_age(agerange):\n",
    "        agerange=agerange.replace('+','') # remove the + from 90+\n",
    "        start=agerange.split('_')[0]\n",
    "        return int(start)\n",
    "\n",
    "    age_bands.sort(key=min_age)\n",
    "\n",
    "\n",
    "    # building the dataframe for deaths\n",
    "\n",
    "    death_df = pd.DataFrame(index=death_index_d, columns = (\"DailyDeaths\", \"F_0_to_4\", \"F_5_to_9\", \"F_10_to_14\", \"F_15_to_19\", \"F_20_to_24\", \"F_25_to_29\", \"F_30_to_34\", \"F_35_to_39\", \"F_40_to_44\", \"F_45_to_49\", \"F_50_to_54\", \"F_55_to_59\", \"F_60_to_64\", \"F_65_to_69\", \"F_70_to_74\", \"F_75_to_79\", \"F_80_to_84\", \"F_85_to_89\", \"F_90_to_94\", \"F_90+\", \"M_0_to_4\", \"M_5_to_9\", \"M_10_to_14\", \"M_15_to_19\", \"M_20_to_24\", \"M_25_to_29\", \"M_30_to_34\", \"M_35_to_39\", \"M_40_to_44\", \"M_45_to_49\", \"M_50_to_54\", \"M_55_to_59\", \"M_60_to_64\", \"M_65_to_69\", \"M_70_to_74\", \"M_75_to_79\", \"M_80_to_84\", \"M_85_to_89\", \"M_90_to_94\", \"M_90+\"))\n",
    "\n",
    "    # filling the data frame\n",
    "\n",
    "    ## filling in the gender / case / age_range data (yes this is a bit redundant – will clean up if I have time. Logic is needed though)\n",
    "\n",
    "\n",
    "    for dictionary in sex_data:\n",
    "        date=parse_date(dictionary['date'])\n",
    "  \n",
    "        for item in dictionary['femaleCases']:\n",
    "           \n",
    "            if item['age'] == '0_to_4':\n",
    "                value= float(item['value']) if item['value'] !=None else 0.0\n",
    "                death_df.loc[date, \"F_0_to_4\"]= value\n",
    "            if item['age'] == '5_to_9':\n",
    "                value= float(item['value']) if item['value'] !=None else 0.0\n",
    "                death_df.loc[date, \"F_5_to_9\"]= value\n",
    "            if item['age'] == '10_to_14':\n",
    "                value= float(item['value']) if item['value'] !=None else 0.0\n",
    "                death_df.loc[date, \"F_10_to_14\"]= value\n",
    "            if item['age'] == '15_to_19':\n",
    "                value= float(item['value']) if item['value'] !=None else 0.0\n",
    "                death_df.loc[date, \"F_15_to_19\"]= value\n",
    "            if item['age'] == '20_to_24':\n",
    "                value= float(item['value']) if item['value'] !=None else 0.0\n",
    "                death_df.loc[date, \"F_20_to_24\"]= value\n",
    "            if item['age'] == '25_to_29':\n",
    "                value= float(item['value']) if item['value'] !=None else 0.0\n",
    "                death_df.loc[date, \"F_25_to_29\"]= value\n",
    "            if item['age'] == '30_to_34':\n",
    "                value= float(item['value']) if item['value'] !=None else 0.0\n",
    "                death_df.loc[date, \"F_30_to_34\"]= value\n",
    "            if item['age'] == '35_to_39':\n",
    "                value= float(item['value']) if item['value'] !=None else 0.0\n",
    "                death_df.loc[date, \"F_35_to_39\"]= value\n",
    "            if item['age'] == '40_to_44':\n",
    "                value= float(item['value']) if item['value'] !=None else 0.0\n",
    "                death_df.loc[date, \"F_40_to_44\"]= value\n",
    "            if item['age'] == '45_to_49':\n",
    "                value= float(item['value']) if item['value'] !=None else 0.0\n",
    "                death_df.loc[date, \"F_45_to_49\"]= value\n",
    "            if item['age'] == '50_to_54':\n",
    "                value= float(item['value']) if item['value'] !=None else 0.0\n",
    "                death_df.loc[date, \"F_50_to_54\"]= value\n",
    "            if item['age'] == '55_to_59':\n",
    "                value= float(item['value']) if item['value'] !=None else 0.0\n",
    "                death_df.loc[date, \"F_55_to_59\"]= value\n",
    "            if item['age'] == '60_to_64':\n",
    "                value= float(item['value']) if item['value'] !=None else 0.0\n",
    "                death_df.loc[date, \"F_60_to_64\"]= value\n",
    "            if item['age'] == '65_to_69':\n",
    "                value= float(item['value']) if item['value'] !=None else 0.0\n",
    "                death_df.loc[date, \"F_65_to_69\"]= value\n",
    "            if item['age'] == '70_to_74':\n",
    "                value= float(item['value']) if item['value'] !=None else 0.0\n",
    "                death_df.loc[date, \"F_70_to_74\"]= value\n",
    "            if item['age'] == '80_to_84':\n",
    "                value= float(item['value']) if item['value'] !=None else 0.0\n",
    "                death_df.loc[date, \"F_80_to_84\"]= value\n",
    "            if item['age'] == '85_to_89':\n",
    "                value= float(item['value']) if item['value'] !=None else 0.0\n",
    "                death_df.loc[date, \"F_85_to_89\"]= value\n",
    "            if item['age'] == '90_to_94':\n",
    "                value= float(item['value']) if item['value'] !=None else 0.0\n",
    "                death_df.loc[date, \"F_90_to_94\"]= value\n",
    "            if item['age'] == '90+':\n",
    "                value= float(item['value']) if item['value'] !=None else 0.0\n",
    "                death_df.loc[date, \"F_90+\"]= value\n",
    "        for item in dictionary['maleCases']:\n",
    "            if item['age'] == '0_to_4':\n",
    "                value= float(item['value']) if item['value'] !=None else 0.0\n",
    "                death_df.loc[date, \"M_0_to_4\"]= value\n",
    "            if item['age'] == '5_to_9':\n",
    "                value= float(item['value']) if item['value'] !=None else 0.0\n",
    "                death_df.loc[date, \"M_5_to_9\"]= value\n",
    "            if item['age'] == '10_to_14':\n",
    "                value= float(item['value']) if item['value'] !=None else 0.0\n",
    "                death_df.loc[date, \"M_10_to_14\"]= value\n",
    "            if item['age'] == '15_to_19':\n",
    "                value= float(item['value']) if item['value'] !=None else 0.0\n",
    "                death_df.loc[date, \"M_15_to_19\"]= value\n",
    "            if item['age'] == '20_to_24':\n",
    "                value= float(item['value']) if item['value'] !=None else 0.0\n",
    "                death_df.loc[date, \"M_20_to_24\"]= value\n",
    "            if item['age'] == '25_to_29':\n",
    "                value= float(item['value']) if item['value'] !=None else 0.0\n",
    "                death_df.loc[date, \"M_25_to_29\"]= value\n",
    "            if item['age'] == '30_to_34':\n",
    "                value= float(item['value']) if item['value'] !=None else 0.0\n",
    "                death_df.loc[date, \"M_30_to_34\"]= value\n",
    "            if item['age'] == '35_to_39':\n",
    "                value= float(item['value']) if item['value'] !=None else 0.0\n",
    "                death_df.loc[date, \"M_35_to_39\"]= value\n",
    "            if item['age'] == '40_to_44':\n",
    "                value= float(item['value']) if item['value'] !=None else 0.0\n",
    "                death_df.loc[date, \"M_40_to_44\"]= value\n",
    "            if item['age'] == '45_to_49':\n",
    "                value= float(item['value']) if item['value'] !=None else 0.0\n",
    "                death_df.loc[date, \"M_45_to_49\"]= value\n",
    "            if item['age'] == '50_to_54':\n",
    "                value= float(item['value']) if item['value'] !=None else 0.0\n",
    "                death_df.loc[date, \"M_50_to_54\"]= value\n",
    "            if item['age'] == '55_to_59':\n",
    "                value= float(item['value']) if item['value'] !=None else 0.0\n",
    "                death_df.loc[date, \"M_55_to_59\"]= value\n",
    "            if item['age'] == '60_to_64':\n",
    "                value= float(item['value']) if item['value'] !=None else 0.0\n",
    "                death_df.loc[date, \"M_60_to_64\"]= value\n",
    "            if item['age'] == '65_to_69':\n",
    "                value= float(item['value']) if item['value'] !=None else 0.0\n",
    "                death_df.loc[date, \"M_65_to_69\"]= value\n",
    "            if item['age'] == '70_to_74':\n",
    "                value= float(item['value']) if item['value'] !=None else 0.0\n",
    "                death_df.loc[date, \"M_70_to_74\"]= value\n",
    "            if item['age'] == '80_to_84':\n",
    "                value= float(item['value']) if item['value'] !=None else 0.0\n",
    "                death_df.loc[date, \"M_80_to_84\"]= value\n",
    "            if item['age'] == '85_to_89':\n",
    "                value= float(item['value']) if item['value'] !=None else 0.0\n",
    "                death_df.loc[date, \"M_85_to_89\"]= value\n",
    "            if item['age'] == '90_to_94':\n",
    "                value= float(item['value']) if item['value'] !=None else 0.0\n",
    "                death_df.loc[date, \"M_90_to_94\"]= value\n",
    "            if item['age'] == '90+':\n",
    "                value= float(item['value']) if item['value'] !=None else 0.0\n",
    "                death_df.loc[date, \"M_90+\"]= value\n",
    "\n",
    "    ## filling in the daily deaths data into the same datframe \n",
    "\n",
    "    for entry in death_data:    # could probably use this method for the gender data to save lines of code... try if I have time\n",
    "\n",
    "        date = parse_date(entry[\"date\"])\n",
    "\n",
    "        if pd.isna(death_df.loc[date, \"DailyDeaths\"]):\n",
    "\n",
    "            value = float(entry[\"deaths\"]) if entry[\"deaths\"] !=None else 0.0\n",
    "\n",
    "            death_df.loc[date, \"DailyDeaths\"] = value\n",
    "\n",
    "\n",
    "    death_df.fillna(0.0, inplace=True) # fill in the rest of the NaNs with 0.0\n",
    "\n",
    "    return death_df\n",
    "\n",
    "death_df = death_gender_wrangle(death_data, sex_data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download current data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Give your users an option to refresh the dataset - a \"refresh\" button will do. The button callback should\n",
    "* call the code that accesses the API and download some fresh raw data;\n",
    "* wrangle that data into a dataframe and update the corresponding (global) variable for plotting;\n",
    "* optionally: force a redraw of the graph and give the user some fredback.\n",
    "\n",
    "Once you get it to work, you may want to wrap your API call inside an exception handler, so that the user is informed, the \"canned\" data are not overwritten and nothing crashes if for any reason the server cannot be reached or data are not available.\n",
    "\n",
    "After you refresh the data, graphs will not update until the user interacts with a widget. You can trick ```iPywidgets``` into redrawing the graph by simulating interaction, as in the ```refresh_graph``` function we define in the Graph and Analysis section below.\n",
    "\n",
    "Clicking on the button below just generates some more random data and refreshes the graph. The button should read *Fetch Data*. If you see anything else, take a deep breath :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place your API access code in this function. Do not call this function directly; it will be called by \n",
    "# the button callback. \n",
    "def access_api():\n",
    "    \"\"\" Accesses the PHE API. Returns raw data in the same format as data loaded from the \"canned\" JSON file. \"\"\"\n",
    "\n",
    "    ### calling the pcr_comp data ###\n",
    "\n",
    "    filters_pcr_comp = ['areaType=overview']    # creating filter \n",
    "    structure_pcr_comp = {\"date\": \"date\", \"newPCR\": \"newPCRTestsByPublishDate\", \"plannedPCR\": \"plannedPCRCapacityByPublishDate\",}   # creating structure\n",
    "\n",
    "    api_pcr_comp = Cov19API(filters=filters_pcr_comp, structure=structure_pcr_comp)     # calling the API with the filters & structures\n",
    "    pcr_comp_data_new = api_pcr_comp.get_json()     # getting the json data into a variable\n",
    "\n",
    "    ### calling the vax_occ data ###\n",
    "\n",
    "    sick_vax_filters = ['areaType=overview'] # note each metric-value pair is inside one string\n",
    "    sick_vax_structure = {\n",
    "        \"date\": \"date\",\n",
    "        \"cumAdmin\":\"cumAdmissions\",\n",
    "        \"occMVBeds\": \"covidOccupiedMVBeds\",\n",
    "        \"cumVax1\": \"cumPeopleVaccinatedFirstDoseByPublishDate\",\n",
    "        \"cumVax2\": \"cumPeopleVaccinatedSecondDoseByPublishDate\",\n",
    "        \"cumVax3\": \"cumPeopleVaccinatedThirdInjectionByPublishDate\",\n",
    "    }\n",
    "\n",
    "    sick_vax_api = Cov19API(filters=sick_vax_filters, structure=sick_vax_structure)\n",
    "    sick_vax_data_new = sick_vax_api.get_json()\n",
    "\n",
    "    ### calling the cas nation data ###\n",
    "\n",
    "    # filters for each nation\n",
    "\n",
    "    cas_nation_filters_eng = [\n",
    "        'areaType=Nation', \"areaName=England\" # \n",
    "    ]\n",
    "\n",
    "    cas_nation_filters_wales = [\n",
    "        'areaType=Nation', \"areaName=Wales\" # \n",
    "    ]\n",
    "\n",
    "    cas_nation_filters_scot = [\n",
    "        'areaType=Nation', \"areaName=Scotland\" # \n",
    "    ]\n",
    "\n",
    "    cas_nation_filters_northi = [\n",
    "        'areaType=Nation', \"areaName=Northern Ireland\" # \n",
    "    ]\n",
    "\n",
    "    # structure for the data\n",
    "\n",
    "    cas_nation_structure = {\n",
    "        \"date\": \"date\",\n",
    "        \"areaName\": \"areaName\",\n",
    "        \"newCases\": \"newCasesByPublishDate\"\n",
    "    }\n",
    "\n",
    "    # including additonal logic here to combine data and make future function calls easier\n",
    "\n",
    "    cas_nation_api_eng = Cov19API(filters=cas_nation_filters_eng, structure=cas_nation_structure)\n",
    "    cas_nation_data_eng = cas_nation_api_eng.get_json()\n",
    "\n",
    "    cas_nation_api_scot = Cov19API(filters=cas_nation_filters_scot, structure=cas_nation_structure)\n",
    "    cas_nation_data_scot = cas_nation_api_scot.get_json()\n",
    "\n",
    "    cas_nation_api_wales = Cov19API(filters=cas_nation_filters_wales, structure=cas_nation_structure)\n",
    "    cas_nation_data_wales = cas_nation_api_wales.get_json()\n",
    "\n",
    "    cas_nation_api_northi = Cov19API(filters=cas_nation_filters_northi, structure=cas_nation_structure)\n",
    "    cas_nation_data_northi = cas_nation_api_northi.get_json()\n",
    "\n",
    "    cas_nat_data_new = [cas_nation_data_eng, cas_nation_data_scot, cas_nation_data_wales, cas_nation_data_northi] # combining the data\n",
    "\n",
    "    ### calling the death gender data ###\n",
    "\n",
    "    # defining the filters\n",
    "\n",
    "    death_filters = [\n",
    "        'areaType=Overview'\n",
    "    ]\n",
    "\n",
    "    sex_filter = [\n",
    "        'areaType=nation',\n",
    "        'areaName=England', # remember to highlight this\n",
    "    ]\n",
    "\n",
    "    # defining the structure\n",
    "\n",
    "    death_structure = {\n",
    "        \"date\": \"date\",\n",
    "        \"deaths\": \"newDailyNsoDeathsByDeathDate\",\n",
    "    }\n",
    "\n",
    "    sex_structure = {\n",
    "        \"date\": \"date\",\n",
    "        \"femaleCases\": \"femaleCases\",\n",
    "        \"maleCases\": \"maleCases\",\n",
    "    }\n",
    "\n",
    "\n",
    "    death_api = Cov19API(filters=death_filters, structure=death_structure)  # calling the API for the deaths data\n",
    "    death_data_new = death_api.get_json()\n",
    "\n",
    "    sex_api = Cov19API(filters=sex_filter, structure=sex_structure)     # calling the APi for the gender + agebands data\n",
    "    sex_data_new=sex_api.get_json()\n",
    "\n",
    "    return {'pcrcompdata' : pcr_comp_data_new, 'vaxoccdata' : sick_vax_data_new, 'casnatdata' : cas_nat_data_new, 'deathdata' : death_data_new, 'genderdata' : sex_data_new} # return data read from the API as a dictionary to make it easy to call the right data later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cfdf52935bb4aa0aa19419d96e499d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='info', description='Refresh Data', icon='download', style=ButtonStyle(), tooltip='Click r…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Printout from this function will be lost in Voila unless captured in an\n",
    "# output widget - therefore, we give feedback to the user by changing the \n",
    "# appearance of the button\n",
    "def api_button_callback(button):\n",
    "    \"\"\" Button callback - it must take the button as its parameter (unused in this case).\n",
    "    Accesses API, wrangles data, updates global variable df used for plotting. \"\"\"\n",
    "    # Get fresh data from the API. If you have time, include some error handling\n",
    "    # around this call.\n",
    "\n",
    "    try:\n",
    "        apidata=access_api()\n",
    "    except ConnectionError as ConnectionErr:\n",
    "        print(\"We could not connect wit the publicly hosted database because the internet connection broke off. Your last refreshed data is still available and has not been overwritten\")\n",
    "\n",
    "    # wrangle the data and overwrite the dataframe for plotting\n",
    "\n",
    "    # for pcr_comp\n",
    "    global pcr_comp_df\n",
    "    pcr_comp_df=pcr_comp_wrangle(apidata['pcrcompdata'])\n",
    "\n",
    "    # for vaxx occ\n",
    "\n",
    "    global sick_vax_df\n",
    "    sick_vax_df = vax_occ_wrangle(apidata['vaxoccdata'])\n",
    "\n",
    "    global cas_nat_df_d\n",
    "    cas_nat_df_d = cas_nation_wrangle(apidata['casnatdata'])\n",
    "\n",
    "    global death_df\n",
    "    death_df = death_gender_wrangle(apidata['deathdata'], apidata['genderdata'])\n",
    "\n",
    "\n",
    "\n",
    "    # the graph won't refresh until the user interacts with the widget.\n",
    "    # this function simulates the interaction, see Graph and Analysis below.\n",
    "    # you can omit this step in the first instance\n",
    "    refresh_graph()\n",
    "    # after all is done, you can switch the icon on the button to a \"check\" sign\n",
    "    # and optionally disable the button - it won't be needed again. You can use icons\n",
    "    # \"unlink\" or \"times\" and change the button text to \"Unavailable\" in case the \n",
    "    # api call fails.\n",
    "    apibutton.icon=\"check\"\n",
    "    # apibutton.disabled=True\n",
    "\n",
    "    \n",
    "apibutton=wdg.Button(\n",
    "    description='Refresh Data', # you may want to change this...\n",
    "    disabled=False,\n",
    "    button_style='info', # 'success', 'info', 'warning', 'danger' or ''\n",
    "    tooltip=\"Click ro refresh data\",\n",
    "    # FontAwesome names without the `fa-` prefix - try \"download\"\n",
    "    icon='download'\n",
    ")\n",
    "\n",
    "# remember to register your button callback function with the button\n",
    "apibutton.on_click(api_button_callback) # the name of your function inside these brackets\n",
    "\n",
    "display(apibutton)\n",
    "\n",
    "# run all cells before clicking on this button"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graphs and Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Include at least one graph with interactive controls, as well as some instructions for the user and/or comments on what the graph represents and how it should be explored (this example shows two random walks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Header pcr comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e46865a74384f36987fafd9a6eae082",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SelectMultiple(description='Categories', index=(0, 1), options=('newPCR', 'plannedPCR'), rows=2, value=('newPC…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc8d2a85d74b4006af7be8ae8814b0d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### having seperate code boxed to plot charts individually? and provide descriptions? probably better\n",
    "\n",
    "\n",
    "\n",
    "### pcr_comp plotting ###\n",
    "pcr_cols=wdg.SelectMultiple(\n",
    "    options=['newPCR', 'plannedPCR'], # could add \"delta\" later\n",
    "    value=['newPCR', 'plannedPCR'], # initial value\n",
    "    rows=2, # rows of the selection box\n",
    "    description='Categories',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "\n",
    "def pcr_comp_graph(graphcolumns):\n",
    "    # our callback function.\n",
    "    ncols=len(graphcolumns)\n",
    "    if ncols>0:\n",
    "        pcr_comp_df.plot(kind='line', y=list(graphcolumns)) # graphcolumns is a tuple - we need a list\n",
    "        plt.show() # important - graphs won't update properly if this is missing\n",
    "    else:\n",
    "        # if the user has not selected any column, print a message instead\n",
    "        print(\"Click to select data for graph\")\n",
    "        print(\"(CTRL-Click to select more than one category)\")\n",
    "    \n",
    "# keep calling age_graph(graphcolumns=value_of_agecols); capture output in widget output    \n",
    "\n",
    "\n",
    "####\n",
    "\n",
    "graph_pcr_comp=wdg.interactive_output(pcr_comp_graph, {'graphcolumns': pcr_cols})\n",
    "\n",
    "display(pcr_cols, graph_pcr_comp)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Header Vax Occ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e8e72eec4ed45aaab565e96b6907eee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(SelectMultiple(description='Vaccines', index=(0, 1, 2), options=('cumVax1', 'cumVax2', 'cumVax3…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab9f54cd3ca44ca7a0e32eb65cc49c4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## vax_occ plotting ###\n",
    "\n",
    "vaxcols=wdg.SelectMultiple(\n",
    "    options=['cumVax1', 'cumVax2', 'cumVax3'], \n",
    "    value=['cumVax1', 'cumVax2', \"cumVax3\"],\n",
    "    rows=3, \n",
    "    description='Vaccines',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "occcols=wdg.SelectMultiple(     # turn this into radio to make clear multi select doesn work? Can multi select work?\n",
    "    options=['occMVBeds', \"cumAdmin\"], \n",
    "    value=['occMVBeds', \"cumAdmin\" ], \n",
    "    rows=2, \n",
    "    description='Sick Metrics',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "\n",
    "vax_occ_scale=wdg.RadioButtons(\n",
    "    options=['linear', 'log'],\n",
    "#    value='pineapple', # Defaults to 'pineapple'\n",
    "#    layout={'width': 'max-content'}, # If the items' names are long\n",
    "    description='Scale:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "controls=wdg.HBox([vaxcols, occcols, vax_occ_scale])\n",
    "\n",
    "def vax_occ_graph(graphcolumns, ycolumns, gscale):   # check here which values we should name / does it matter?\n",
    "    \n",
    "    ncols=len(graphcolumns)\n",
    "\n",
    "    if gscale=='linear':    # controlling for the liner/log scale\n",
    "        logscale=False\n",
    "    else:\n",
    "        logscale=True\n",
    "\n",
    "    if occcols.value == (\"occMVBeds\",):   # why does this work only this way while got gscale, etc. the string works? !!!!\n",
    "        yaxis_state = \"occMVBeds\"\n",
    "        yaxis_desc = \"Cummulative Admissions\"\n",
    "    else:                                           # controlling for the secondary y axis\n",
    "        yaxis_state = \"cumAdmin\"\n",
    "        yaxis_desc = \"MV Bed Occupancy\"\n",
    "\n",
    "\n",
    "    if ncols>0:\n",
    "        print(yaxis_state)\n",
    "        sick_vax_df.plot( y=list(graphcolumns), logy=logscale, use_index=True) \n",
    "        ax = sick_vax_df[yaxis_state].plot(secondary_y=True, logy=logscale, color='k')  # plotting a secondary y axis to plot data at different dimensions\n",
    "        ax.set_ylabel(yaxis_desc)\n",
    "        plt.show() \n",
    "    \n",
    "    else:\n",
    "        # if the user has not selected any column, print a message instead\n",
    "        print(\"Click to select data for graph\")\n",
    "        print(\"(CTRL-Click to select more than one category)\")\n",
    "    \n",
    "# keep calling age_graph(graphcolumns=value_of_agecols); capture output in widget output    \n",
    "graph_vax_occ=wdg.interactive_output(vax_occ_graph, {'graphcolumns': vaxcols, \"ycolumns\" : occcols, \"gscale\":vax_occ_scale})\n",
    "#output2=wdg.interactive_output(age_graph, {'graphcolumns': occcols})\n",
    "\n",
    "display(controls, graph_vax_occ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cas Nat Header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac41f5124e834fea8bb9c1924061c9e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(SelectMultiple(description='Nations', index=(0, 1, 2, 3), options=('England', 'Scotland', 'Wale…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "640cc9a946084fc6bbce932c7ce54966",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6505a53ad58f48728b77030f016f91ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntSlider(value=3, continuous_update=False, description='Months:', max=12, min=1), IntSlider(va…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "natcols=wdg.SelectMultiple(\n",
    "    options=['England', 'Scotland', 'Wales', 'Northern Ireland'], # options available\n",
    "    value=['England', 'Scotland', 'Wales', 'Northern Ireland'], # initial value\n",
    "    rows=4, # rows of the selection box\n",
    "    description='Nations',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "timescale=wdg.RadioButtons(\n",
    "    options=['Daily', 'Monthly'],\n",
    "    description='Scale:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "timeslider=wdg.IntSlider(\n",
    "    value=3,\n",
    "    min=1,\n",
    "    max=12,\n",
    "    step=1,\n",
    "    description='Months:',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d'\n",
    ")\n",
    "\n",
    "timeslider2=wdg.IntSlider(\n",
    "    value=1,\n",
    "    min=1,\n",
    "    max=31,\n",
    "    step=1,\n",
    "    description='Days:',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d'\n",
    ")\n",
    "\n",
    "controls=wdg.HBox([natcols, timescale])\n",
    "sliderbox=wdg.HBox([timeslider, timeslider2])\n",
    "\n",
    "\n",
    "\n",
    "def cas_nat_graph(nationcolumns, tscale, timevalue, timevalue2):\n",
    "\n",
    "    # our callback function.\n",
    "    ncols=len(nationcolumns)\n",
    "    \n",
    "    m_value = str(timeslider.value) + \"m\"\n",
    "    d_value = str(timeslider2.value) + \"d\"\n",
    "\n",
    "    if ncols>0:\n",
    "\n",
    "        if  tscale=='Daily':\n",
    "            cas_nat_df_dd = cas_nat_df_d.resample(d_value).sum() # had to use the dd naming to have a new variable -> could be cleaner\n",
    "            cas_nat_df_dd.plot( y=list(nationcolumns))\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        else: \n",
    "            cas_nat_df_m = cas_nat_df_d.resample(m_value).sum()\n",
    "            cas_nat_df_m.plot( y=list(nationcolumns), kind='bar', use_index=True)\n",
    "            plt.show()\n",
    "            slider_dis = False\n",
    "            print(slider_dis)\n",
    "            return slider_dis\n",
    "\n",
    "    else:\n",
    "        \n",
    "        print(\"Click to select data for graph\")\n",
    "        print(\"(CTRL-Click to select more than one category)\")\n",
    "    \n",
    "  \n",
    "graph_cas_nat=wdg.interactive_output(cas_nat_graph, {'nationcolumns': natcols, \"tscale\": timescale, \"timevalue\": timeslider, \"timevalue2\":timeslider2}) # clean up slider names + order\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "display(controls, graph_cas_nat, sliderbox)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Death Gender Header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b017923c1e9423e97f82dda4e82f8c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(SelectMultiple(description='Female Age Bands', index=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b9ce6d0d3da406bb1e81ad8b9427ca3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "female_age_cols=wdg.SelectMultiple(\n",
    "    options=[\"F_0_to_4\", \"F_5_to_9\", \"F_10_to_14\", \"F_15_to_19\", \"F_20_to_24\", \"F_25_to_29\", \"F_30_to_34\", \"F_35_to_39\", \"F_40_to_44\", \"F_45_to_49\", \"F_50_to_54\", \"F_55_to_59\", \"F_60_to_64\", \"F_65_to_69\", \"F_70_to_74\", \"F_75_to_79\", \"F_80_to_84\", \"F_85_to_89\", \"F_90_to_94\", \"F_90+\"],\n",
    "    value=[\"F_0_to_4\", \"F_5_to_9\", \"F_10_to_14\", \"F_15_to_19\", \"F_20_to_24\", \"F_25_to_29\", \"F_30_to_34\", \"F_35_to_39\", \"F_40_to_44\", \"F_45_to_49\", \"F_50_to_54\", \"F_55_to_59\", \"F_60_to_64\", \"F_65_to_69\", \"F_70_to_74\", \"F_75_to_79\", \"F_80_to_84\", \"F_85_to_89\", \"F_90_to_94\", \"F_90+\"],\n",
    "    rows= 20, # rows of the selection box\n",
    "    description='Female Age Bands',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "male_age_cols=wdg.SelectMultiple(\n",
    "    options=[\"M_0_to_4\", \"M_5_to_9\", \"M_10_to_14\", \"M_15_to_19\", \"M_20_to_24\", \"M_25_to_29\", \"M_30_to_34\", \"M_35_to_39\", \"M_40_to_44\", \"M_45_to_49\", \"M_50_to_54\", \"M_55_to_59\", \"M_60_to_64\", \"M_65_to_69\", \"M_70_to_74\", \"M_75_to_79\", \"M_80_to_84\", \"M_85_to_89\", \"M_90_to_94\", \"M_90+\"],\n",
    "    value=[],\n",
    "    rows= 20, # rows of the selection box\n",
    "    description='Male Age Bands',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "timeslider3=wdg.IntSlider(\n",
    "    value=9,\n",
    "    min=1,\n",
    "    max=12,\n",
    "    step=1,\n",
    "    description='Monthly Intervall',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d'\n",
    ")\n",
    "\n",
    "controls = wdg.HBox([female_age_cols, male_age_cols, timeslider3])\n",
    "\n",
    "def death_gender_graph(femagecols, menagecols, timevalue):\n",
    "\n",
    "    # our callback function.\n",
    "    ncols=len(femagecols)\n",
    "    m_value = str(timeslider3.value) + \"m\"\n",
    "\n",
    "\n",
    "    if ncols>0:\n",
    "        death_df_mm= death_df.resample(m_value).sum()\n",
    "        death_df_m=death_df.resample(\"1m\").sum()        # explain this in the header -> we are fixing this at a one month intervall to have the right resolution for deaths\n",
    "        death_df_mm.plot(y=list(femagecols + menagecols), kind=\"area\", logy = False, use_index=True, figsize=(20,10)) # graphcolumns is a tuple - we need a list\n",
    "        ax = death_df_m[\"DailyDeaths\"].plot(secondary_y=True, color='k')    # check here if you want daily or resampled data\n",
    "        ax.set_ylabel('Daily Deaths')\n",
    "\n",
    "    else:\n",
    "        \n",
    "        print(\"Click to select data for graph\")\n",
    "        print(\"(CTRL-Click to select more than one category)\")\n",
    "    \n",
    "  \n",
    "graph_death_gender=wdg.interactive_output(death_gender_graph, {'femagecols': female_age_cols, \"menagecols\" : male_age_cols, \"timevalue\": timeslider3}) # clean up slider names + order\n",
    "\n",
    "display(controls, graph_death_gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "### refreshing the charts ###\n",
    "\n",
    "def refresh_graph():\n",
    "    \"\"\" We change the value of the widget in order to force a redraw of the graph;\n",
    "    this is useful when the data have been updated. This is a bit of a gimmick; it\n",
    "    needs to be customised for one of your widgets. \"\"\"\n",
    "\n",
    "    # trying a loop here\n",
    "    chartcontr_lst = [pcr_cols, vaxcols,] # loop over one control widget for eacg graph\n",
    "\n",
    "    for chart in chartcontr_lst:    # go through the steps of changing / unchanging an option\n",
    "\n",
    "        current=pcr_cols.value\n",
    "        if current==chart.options[0]:\n",
    "            other=chart.options[1]\n",
    "        else:\n",
    "            other=chart.options[0]\n",
    "        chart.value=other # forces the redraw\n",
    "        chart.value=current # changing it back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying the dashboard\n",
    "\n",
    "Once your code is ready and you are satisfied with the appearance of the graphs, replace all the text boxes above with the explanations you would like a dashboard user to see. The next step is deploying the dashboard online - there are several [options](https://voila.readthedocs.io/en/stable/deploy.html) for this, we suggest deploying as a [Binder](https://mybinder.org/). This is basically the same technique that has been used to package this tutorial and to deploy this template dashboard. The instructions may seem a bit involved, but the actual steps are surprisingly easy - we will be going through them together during a live session. You will need an account on [GitHub](https://github.com/) for this - if you don't have one already, now it's the time to create it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Author and Copyright Notice** Remember if you deploy this dashboard as a Binder it will be publicly accessible. Take credit for your work! Also acknowledge the data source: *Based on UK Government [data](https://coronavirus.data.gov.uk/) published by [Public Health England](https://www.gov.uk/government/organisations/public-health-england).*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "c6609c9133a6db690f016f49050ce97a9a809177a34a79c19b62b14f5faf7a07"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
