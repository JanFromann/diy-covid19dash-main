{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jan's Covid-19 Dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome 👋\n",
    "\n",
    "This is Jan's Covid Dashboard. If you havent looked at enough corona charts in the last three years, here is your chance to change that!\n",
    "\n",
    "Below you will find a collection of charts that I found interesting, based on the UK goverments official COVID-19 API. You can find the API and documentation [here](https://coronavirus.data.gov.uk/details/developers-guide/main-api).\n",
    "\n",
    "If you have any questions or feedback on this project, drop me an email @ jan@fount.io\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import ipywidgets as wdg\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from uk_covid19 import Cov19API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.rcParams['figure.dpi'] = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Loading Data from Disk ######\n",
    "\n",
    "\n",
    "### pcr_comp json load ###\n",
    "\n",
    "with open(\"pcr_comp.json\", \"rt\") as INFILE:\n",
    "    pcr_data = json.load(INFILE)\n",
    "\n",
    "### vax_occ json load ###\n",
    "\n",
    "with open(\"sick_vax.json\", \"rt\") as INFILE:\n",
    "    sick_vax_data = json.load(INFILE)\n",
    "\n",
    "### cas_nation json load ###\n",
    "\n",
    "with open(\"cas_nation_data.json\", \"rt\") as INFILE:\n",
    "    cas_nat_data = json.load(INFILE)\n",
    "\n",
    "\n",
    "### death_gender_age load ###\n",
    "\n",
    "with open(\"death_data.json\", \"rt\") as INFILE:\n",
    "    death_data = json.load(INFILE)\n",
    "\n",
    "with open(\"sex_data.json\", \"rt\") as INFILE:\n",
    "    sex_data = json.load(INFILE)  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Wrangling Data #######\n",
    "\n",
    "### Pre-requisite Functions ###\n",
    "\n",
    "#function to get the panda of a datestring\n",
    "\n",
    "def parse_date(datestring):\n",
    "    \"\"\" Convert a date string into a pandas datetime object \"\"\"\n",
    "    return pd.to_datetime(datestring, format=\"%Y-%m-%d\")\n",
    "\n",
    "\n",
    "### Wrangling the Data via Functions for each Graph ###\n",
    "\n",
    "### pcr_comp Data Wrangling ###\n",
    "\n",
    "def pcr_comp_wrangle(rawdata):\n",
    "    pcr_comp_data = rawdata['data']\n",
    "    \n",
    "    pcr_dates = [dic[\"date\"] for dic in pcr_comp_data] # getting the dates\n",
    "    pcr_dates.sort()    # sorting the dates\n",
    "\n",
    "     \n",
    "    pcr_startdate = parse_date(pcr_dates[0])    # getting the startdate\n",
    "    pcr_enddate = parse_date(pcr_dates[-1])     # getting the endddate\n",
    "\n",
    "    pcr_index = pd.date_range(pcr_startdate, pcr_enddate, freq='D')     # getting the index for the dataframe\n",
    "\n",
    "\n",
    "    pcr_comp_df = pd.DataFrame(index=pcr_index, columns=[\"newPCR\", \"plannedPCR\"])   # creating the dataframe\n",
    "\n",
    "    # filling the the dataframe\n",
    "\n",
    "    for entry in pcr_comp_data:\n",
    "\n",
    "        date = parse_date(entry[\"date\"])\n",
    "\n",
    "        for column in [\"newPCR\", \"plannedPCR\"]:     # learning: make sure you have the same column name for the data frame and the list / json file\n",
    "\n",
    "         if pd.isna(pcr_comp_df.loc[date, column]):\n",
    "\n",
    "            value = float(entry[column]) if entry[column] !=None else 0.0\n",
    "\n",
    "            pcr_comp_df.loc[date, column] = value\n",
    "\n",
    "    pcr_comp_df.fillna(0.0, inplace=True)   \n",
    "    return pcr_comp_df\n",
    "\n",
    "\n",
    "pcr_comp_df = pcr_comp_wrangle(pcr_data) # mangling the data initally when loading \n",
    "\n",
    "\n",
    "###\n",
    "\n",
    "\n",
    "### vax_occ Data Wrangling ###\n",
    "\n",
    "def vax_occ_wrangle(rawdata):\n",
    "\n",
    "    sick_vax_data = rawdata['data']\n",
    "    #sick_vax_datalist = sick_vax_data[\"data\"]   # getting the data list\n",
    "\n",
    "\n",
    "    sick_vax_dates = [dictionary[\"date\"] for dictionary in sick_vax_data ]       # getting start and end dates\n",
    "    sick_vax_dates.sort()\n",
    "\n",
    "    sick_vax_startdate = parse_date(sick_vax_dates[0])  \n",
    "    sick_vax_enddate = parse_date(sick_vax_dates[-1])\n",
    "\n",
    "    sick_vax_index = pd.date_range(sick_vax_startdate, sick_vax_enddate, freq='D')      # creating the index based on dates\n",
    "\n",
    "    sick_vax_df = pd.DataFrame(index=sick_vax_index, columns=[\"cumAdmin\", \"occMVBeds\", \"cumVax1\", \"cumVax2\", \"cumVax3\"])    # creating the data frame\n",
    "\n",
    "    #   fillinf the data frame\n",
    "\n",
    "    for entry in sick_vax_data:\n",
    "\n",
    "     date = parse_date(entry[\"date\"])\n",
    "\n",
    "     for column in [\"cumAdmin\", \"occMVBeds\", \"cumVax1\", \"cumVax2\", \"cumVax3\"]: \n",
    "\n",
    "            if pd.isna(sick_vax_df.loc[date, column]):\n",
    "\n",
    "              value = float(entry[column]) if entry[column] !=None else 0.0\n",
    "\n",
    "              sick_vax_df.loc[date, column] = value\n",
    "\n",
    "    sick_vax_df.fillna(0.0, inplace=True)\n",
    "    return sick_vax_df\n",
    "\n",
    "sick_vax_df = vax_occ_wrangle(sick_vax_data)    # mangling the data initially when loading\n",
    "\n",
    "### \n",
    "\n",
    "\n",
    "\n",
    "### cas_nation Data Wrangling ###\n",
    "\n",
    "def cas_nation_wrangle(rawdata):\n",
    "\n",
    "    new_case_nat_data = []                          # here we are getting a list of api data structures. We are iterating over them them to get the data list and in paralell combining that data into one variable\n",
    "    for data in rawdata:\n",
    "        new_case_nat_data += data['data']\n",
    "\n",
    "    cas_nat_data = new_case_nat_data \n",
    "\n",
    "    #cas_nat_data = rawdata\n",
    "    cas_nat_dates_raw=[dictionary['date'] for dictionary in cas_nat_data ]\n",
    "    cas_nat_dates_raw.sort()\n",
    "\n",
    "\n",
    "    cas_nat_dates_dic = {date for date in cas_nat_dates_raw} # removing duplicates by transforming into a dictionary and back into a sorted list\n",
    "    cas_nat_dates = list(cas_nat_dates_dic)\n",
    "    cas_nat_dates.sort()    # sorting the dates (not required but I wanted the data clean)\n",
    "\n",
    "    cas_nat_startdate=parse_date(cas_nat_dates[0])  # getting the start and end dates\n",
    "    cas_nat_enddate=parse_date(cas_nat_dates[-1])\n",
    "\n",
    "    #cas_nat_index_m=pd.date_range(cas_nat_startdate, cas_nat_enddate, freq='M') # creating the index for the dataframe with monthly frequency (do i need this? currently not returned)\n",
    "    cas_nat_index_d=pd.date_range(cas_nat_startdate, cas_nat_enddate, freq='D') # creating the index for the dataframe with daily frequency\n",
    "\n",
    "    cas_nat_df_d = pd.DataFrame(index=cas_nat_index_d, columns = (\"England\", \"Scotland\", \"Wales\", \"Northern Ireland\"))  # building a dataframe based on daily frequency\n",
    "\n",
    "    #cas_nat_df_m = pd.DataFrame(index=cas_nat_index_m, columns = (\"England\", \"Scotland\", \"Wales\", \"Northern Ireland\"))\n",
    "    #print(cas_nat_df_m) # building a dataframe based on monthly frequency\n",
    "\n",
    "    # filling the dataframes by iterating over the data and having conditional löogic based on the Area Name and Date columns\n",
    "\n",
    "    for dictionary in cas_nat_data:\n",
    "        date=parse_date(dictionary['date'])\n",
    "\n",
    "        if dictionary['areaName'] == \"England\":\n",
    "\n",
    "            value= float(dictionary['newCases']) if dictionary['newCases']!=None else 0.0\n",
    "\n",
    "            cas_nat_df_d.loc[date, \"England\"]= value\n",
    "\n",
    "        if dictionary['areaName'] == \"Scotland\":\n",
    "\n",
    "            value= float(dictionary['newCases']) if dictionary['newCases']!=None else 0.0\n",
    "\n",
    "            cas_nat_df_d.loc[date, \"Scotland\"]= value\n",
    "\n",
    "\n",
    "        if dictionary['areaName'] == \"Wales\":\n",
    "\n",
    "            value= float(dictionary['newCases']) if dictionary['newCases']!=None else 0.0\n",
    "\n",
    "            cas_nat_df_d.loc[date, \"Wales\"]= value\n",
    "\n",
    "        if dictionary['areaName'] == \"Northern Ireland\":\n",
    "\n",
    "            value= float(dictionary['newCases']) if dictionary['newCases']!=None else 0.0\n",
    "\n",
    "            cas_nat_df_d.loc[date, \"Northern Ireland\"]= value\n",
    "\n",
    "        cas_nat_df_d.fillna(0.0, inplace=True)  # filling the dataframe with 0.0 for missing values\n",
    "\n",
    "    return cas_nat_df_d\n",
    "\n",
    "cas_nat_df_d = cas_nation_wrangle(cas_nat_data) # mangling the data initially when loading\n",
    "\n",
    "###\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### death_gender_age load ###\n",
    "\n",
    "def death_gender_wrangle(rawdata_death, rawdata_sex):\n",
    "\n",
    "    death_data = rawdata_death['data']\n",
    "    sex_data = rawdata_sex['data']\n",
    "\n",
    "\n",
    "    # getting the timeseries\n",
    "\n",
    "\n",
    "    death_dates_raw =[dictionary['date'] for dictionary in death_data ]\n",
    "\n",
    "    death_dates_dic = {date for date in death_dates_raw} # removing duplicates by transforming into a dictionary and back into a sorted list \n",
    "    death_dates = list(death_dates_dic)\n",
    "    death_dates.sort()\n",
    "\n",
    "    # gettingn start and end dates\n",
    "\n",
    "    death_startdate=parse_date(death_dates[0])\n",
    "    death_enddate=parse_date(death_dates[-1])\n",
    "\n",
    "    death_index_d=pd.date_range(death_startdate, death_enddate, freq='D') # creating the index for the dataframe with daily frequency\n",
    "\n",
    "    # getting female / male cases and the age ranges / is this needed ???\n",
    "\n",
    "    female_cases = [dictionary['femaleCases'] for dictionary in sex_data]\n",
    "    male_cases = [dictionary['maleCases'] for dictionary in sex_data]\n",
    "\n",
    "    age_bands =[]\n",
    "    for item in male_cases:\n",
    "        age_bands += [dictionary['age'] for dictionary in item]\n",
    "\n",
    "    age_bands = list(set(age_bands)) # removing duplicates and sorting (how did sorting here actually happen? Im not sure. But it sorted for all but one age band so Im doing it fully correct below)\n",
    "    age_bands.sort()\n",
    "\n",
    "\n",
    "    def min_age(agerange):\n",
    "        agerange=agerange.replace('+','') # remove the + from 90+\n",
    "        start=agerange.split('_')[0]\n",
    "        return int(start)\n",
    "\n",
    "    age_bands.sort(key=min_age)\n",
    "\n",
    "\n",
    "    # building the dataframe for deaths\n",
    "\n",
    "    death_df = pd.DataFrame(index=death_index_d, columns = (\"DailyDeaths\", \"F_0_to_4\", \"F_5_to_9\", \"F_10_to_14\", \"F_15_to_19\", \"F_20_to_24\", \"F_25_to_29\", \"F_30_to_34\", \"F_35_to_39\", \"F_40_to_44\", \"F_45_to_49\", \"F_50_to_54\", \"F_55_to_59\", \"F_60_to_64\", \"F_65_to_69\", \"F_70_to_74\", \"F_75_to_79\", \"F_80_to_84\", \"F_85_to_89\", \"F_90_to_94\", \"F_90+\", \"M_0_to_4\", \"M_5_to_9\", \"M_10_to_14\", \"M_15_to_19\", \"M_20_to_24\", \"M_25_to_29\", \"M_30_to_34\", \"M_35_to_39\", \"M_40_to_44\", \"M_45_to_49\", \"M_50_to_54\", \"M_55_to_59\", \"M_60_to_64\", \"M_65_to_69\", \"M_70_to_74\", \"M_75_to_79\", \"M_80_to_84\", \"M_85_to_89\", \"M_90_to_94\", \"M_90+\"))\n",
    "\n",
    "    # filling the data frame\n",
    "\n",
    "    ## filling in the gender / case / age_range data (yes this is a bit redundant – will clean up if I have time. Logic is needed though)\n",
    "\n",
    "\n",
    "    for dictionary in sex_data:\n",
    "        date=parse_date(dictionary['date'])\n",
    "  \n",
    "        for item in dictionary['femaleCases']:\n",
    "           \n",
    "            if item['age'] == '0_to_4':\n",
    "                value= float(item['value']) if item['value'] !=None else 0.0\n",
    "                death_df.loc[date, \"F_0_to_4\"]= value\n",
    "            if item['age'] == '5_to_9':\n",
    "                value= float(item['value']) if item['value'] !=None else 0.0\n",
    "                death_df.loc[date, \"F_5_to_9\"]= value\n",
    "            if item['age'] == '10_to_14':\n",
    "                value= float(item['value']) if item['value'] !=None else 0.0\n",
    "                death_df.loc[date, \"F_10_to_14\"]= value\n",
    "            if item['age'] == '15_to_19':\n",
    "                value= float(item['value']) if item['value'] !=None else 0.0\n",
    "                death_df.loc[date, \"F_15_to_19\"]= value\n",
    "            if item['age'] == '20_to_24':\n",
    "                value= float(item['value']) if item['value'] !=None else 0.0\n",
    "                death_df.loc[date, \"F_20_to_24\"]= value\n",
    "            if item['age'] == '25_to_29':\n",
    "                value= float(item['value']) if item['value'] !=None else 0.0\n",
    "                death_df.loc[date, \"F_25_to_29\"]= value\n",
    "            if item['age'] == '30_to_34':\n",
    "                value= float(item['value']) if item['value'] !=None else 0.0\n",
    "                death_df.loc[date, \"F_30_to_34\"]= value\n",
    "            if item['age'] == '35_to_39':\n",
    "                value= float(item['value']) if item['value'] !=None else 0.0\n",
    "                death_df.loc[date, \"F_35_to_39\"]= value\n",
    "            if item['age'] == '40_to_44':\n",
    "                value= float(item['value']) if item['value'] !=None else 0.0\n",
    "                death_df.loc[date, \"F_40_to_44\"]= value\n",
    "            if item['age'] == '45_to_49':\n",
    "                value= float(item['value']) if item['value'] !=None else 0.0\n",
    "                death_df.loc[date, \"F_45_to_49\"]= value\n",
    "            if item['age'] == '50_to_54':\n",
    "                value= float(item['value']) if item['value'] !=None else 0.0\n",
    "                death_df.loc[date, \"F_50_to_54\"]= value\n",
    "            if item['age'] == '55_to_59':\n",
    "                value= float(item['value']) if item['value'] !=None else 0.0\n",
    "                death_df.loc[date, \"F_55_to_59\"]= value\n",
    "            if item['age'] == '60_to_64':\n",
    "                value= float(item['value']) if item['value'] !=None else 0.0\n",
    "                death_df.loc[date, \"F_60_to_64\"]= value\n",
    "            if item['age'] == '65_to_69':\n",
    "                value= float(item['value']) if item['value'] !=None else 0.0\n",
    "                death_df.loc[date, \"F_65_to_69\"]= value\n",
    "            if item['age'] == '70_to_74':\n",
    "                value= float(item['value']) if item['value'] !=None else 0.0\n",
    "                death_df.loc[date, \"F_70_to_74\"]= value\n",
    "            if item['age'] == '80_to_84':\n",
    "                value= float(item['value']) if item['value'] !=None else 0.0\n",
    "                death_df.loc[date, \"F_80_to_84\"]= value\n",
    "            if item['age'] == '85_to_89':\n",
    "                value= float(item['value']) if item['value'] !=None else 0.0\n",
    "                death_df.loc[date, \"F_85_to_89\"]= value\n",
    "            if item['age'] == '90_to_94':\n",
    "                value= float(item['value']) if item['value'] !=None else 0.0\n",
    "                death_df.loc[date, \"F_90_to_94\"]= value\n",
    "            if item['age'] == '90+':\n",
    "                value= float(item['value']) if item['value'] !=None else 0.0\n",
    "                death_df.loc[date, \"F_90+\"]= value\n",
    "        for item in dictionary['maleCases']:\n",
    "            if item['age'] == '0_to_4':\n",
    "                value= float(item['value']) if item['value'] !=None else 0.0\n",
    "                death_df.loc[date, \"M_0_to_4\"]= value\n",
    "            if item['age'] == '5_to_9':\n",
    "                value= float(item['value']) if item['value'] !=None else 0.0\n",
    "                death_df.loc[date, \"M_5_to_9\"]= value\n",
    "            if item['age'] == '10_to_14':\n",
    "                value= float(item['value']) if item['value'] !=None else 0.0\n",
    "                death_df.loc[date, \"M_10_to_14\"]= value\n",
    "            if item['age'] == '15_to_19':\n",
    "                value= float(item['value']) if item['value'] !=None else 0.0\n",
    "                death_df.loc[date, \"M_15_to_19\"]= value\n",
    "            if item['age'] == '20_to_24':\n",
    "                value= float(item['value']) if item['value'] !=None else 0.0\n",
    "                death_df.loc[date, \"M_20_to_24\"]= value\n",
    "            if item['age'] == '25_to_29':\n",
    "                value= float(item['value']) if item['value'] !=None else 0.0\n",
    "                death_df.loc[date, \"M_25_to_29\"]= value\n",
    "            if item['age'] == '30_to_34':\n",
    "                value= float(item['value']) if item['value'] !=None else 0.0\n",
    "                death_df.loc[date, \"M_30_to_34\"]= value\n",
    "            if item['age'] == '35_to_39':\n",
    "                value= float(item['value']) if item['value'] !=None else 0.0\n",
    "                death_df.loc[date, \"M_35_to_39\"]= value\n",
    "            if item['age'] == '40_to_44':\n",
    "                value= float(item['value']) if item['value'] !=None else 0.0\n",
    "                death_df.loc[date, \"M_40_to_44\"]= value\n",
    "            if item['age'] == '45_to_49':\n",
    "                value= float(item['value']) if item['value'] !=None else 0.0\n",
    "                death_df.loc[date, \"M_45_to_49\"]= value\n",
    "            if item['age'] == '50_to_54':\n",
    "                value= float(item['value']) if item['value'] !=None else 0.0\n",
    "                death_df.loc[date, \"M_50_to_54\"]= value\n",
    "            if item['age'] == '55_to_59':\n",
    "                value= float(item['value']) if item['value'] !=None else 0.0\n",
    "                death_df.loc[date, \"M_55_to_59\"]= value\n",
    "            if item['age'] == '60_to_64':\n",
    "                value= float(item['value']) if item['value'] !=None else 0.0\n",
    "                death_df.loc[date, \"M_60_to_64\"]= value\n",
    "            if item['age'] == '65_to_69':\n",
    "                value= float(item['value']) if item['value'] !=None else 0.0\n",
    "                death_df.loc[date, \"M_65_to_69\"]= value\n",
    "            if item['age'] == '70_to_74':\n",
    "                value= float(item['value']) if item['value'] !=None else 0.0\n",
    "                death_df.loc[date, \"M_70_to_74\"]= value\n",
    "            if item['age'] == '80_to_84':\n",
    "                value= float(item['value']) if item['value'] !=None else 0.0\n",
    "                death_df.loc[date, \"M_80_to_84\"]= value\n",
    "            if item['age'] == '85_to_89':\n",
    "                value= float(item['value']) if item['value'] !=None else 0.0\n",
    "                death_df.loc[date, \"M_85_to_89\"]= value\n",
    "            if item['age'] == '90_to_94':\n",
    "                value= float(item['value']) if item['value'] !=None else 0.0\n",
    "                death_df.loc[date, \"M_90_to_94\"]= value\n",
    "            if item['age'] == '90+':\n",
    "                value= float(item['value']) if item['value'] !=None else 0.0\n",
    "                death_df.loc[date, \"M_90+\"]= value\n",
    "\n",
    "    ## filling in the daily deaths data into the same datframe \n",
    "\n",
    "    for entry in death_data:    # could probably use this method for the gender data to save lines of code... try if I have time\n",
    "\n",
    "        date = parse_date(entry[\"date\"])\n",
    "\n",
    "        if pd.isna(death_df.loc[date, \"DailyDeaths\"]):\n",
    "\n",
    "            value = float(entry[\"deaths\"]) if entry[\"deaths\"] !=None else 0.0\n",
    "\n",
    "            death_df.loc[date, \"DailyDeaths\"] = value\n",
    "\n",
    "\n",
    "    death_df.fillna(0.0, inplace=True) # fill in the rest of the NaNs with 0.0\n",
    "\n",
    "    return death_df\n",
    "\n",
    "death_df = death_gender_wrangle(death_data, sex_data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Downloading Current Data #######\n",
    "\n",
    "# Place your API access code in this function. Do not call this function directly; it will be called by \n",
    "\n",
    "# the button callback. \n",
    "def access_api():\n",
    "    \"\"\" Accesses the PHE API. Returns raw data in the same format as data loaded from the \"canned\" JSON file. \"\"\"\n",
    "\n",
    "    ### calling the pcr_comp data ###\n",
    "\n",
    "    filters_pcr_comp = ['areaType=overview']    # creating filter \n",
    "    structure_pcr_comp = {\"date\": \"date\", \"newPCR\": \"newPCRTestsByPublishDate\", \"plannedPCR\": \"plannedPCRCapacityByPublishDate\",}   # creating structure\n",
    "\n",
    "    api_pcr_comp = Cov19API(filters=filters_pcr_comp, structure=structure_pcr_comp)     # calling the API with the filters & structures\n",
    "    pcr_comp_data_new = api_pcr_comp.get_json()     # getting the json data into a variable\n",
    "\n",
    "    ### calling the vax_occ data ###\n",
    "\n",
    "    sick_vax_filters = ['areaType=overview'] # note each metric-value pair is inside one string\n",
    "    sick_vax_structure = {\n",
    "        \"date\": \"date\",\n",
    "        \"cumAdmin\":\"cumAdmissions\",\n",
    "        \"occMVBeds\": \"covidOccupiedMVBeds\",\n",
    "        \"cumVax1\": \"cumPeopleVaccinatedFirstDoseByPublishDate\",\n",
    "        \"cumVax2\": \"cumPeopleVaccinatedSecondDoseByPublishDate\",\n",
    "        \"cumVax3\": \"cumPeopleVaccinatedThirdInjectionByPublishDate\",\n",
    "    }\n",
    "\n",
    "    sick_vax_api = Cov19API(filters=sick_vax_filters, structure=sick_vax_structure)\n",
    "    sick_vax_data_new = sick_vax_api.get_json()\n",
    "\n",
    "    ### calling the cas nation data ###\n",
    "\n",
    "    # filters for each nation\n",
    "\n",
    "    cas_nation_filters_eng = [\n",
    "        'areaType=Nation', \"areaName=England\" # \n",
    "    ]\n",
    "\n",
    "    cas_nation_filters_wales = [\n",
    "        'areaType=Nation', \"areaName=Wales\" # \n",
    "    ]\n",
    "\n",
    "    cas_nation_filters_scot = [\n",
    "        'areaType=Nation', \"areaName=Scotland\" # \n",
    "    ]\n",
    "\n",
    "    cas_nation_filters_northi = [\n",
    "        'areaType=Nation', \"areaName=Northern Ireland\" # \n",
    "    ]\n",
    "\n",
    "    # structure for the data\n",
    "\n",
    "    cas_nation_structure = {\n",
    "        \"date\": \"date\",\n",
    "        \"areaName\": \"areaName\",\n",
    "        \"newCases\": \"newCasesByPublishDate\"\n",
    "    }\n",
    "\n",
    "    # including additonal logic here to combine data and make future function calls easier\n",
    "\n",
    "    cas_nation_api_eng = Cov19API(filters=cas_nation_filters_eng, structure=cas_nation_structure)\n",
    "    cas_nation_data_eng = cas_nation_api_eng.get_json()\n",
    "\n",
    "    cas_nation_api_scot = Cov19API(filters=cas_nation_filters_scot, structure=cas_nation_structure)\n",
    "    cas_nation_data_scot = cas_nation_api_scot.get_json()\n",
    "\n",
    "    cas_nation_api_wales = Cov19API(filters=cas_nation_filters_wales, structure=cas_nation_structure)\n",
    "    cas_nation_data_wales = cas_nation_api_wales.get_json()\n",
    "\n",
    "    cas_nation_api_northi = Cov19API(filters=cas_nation_filters_northi, structure=cas_nation_structure)\n",
    "    cas_nation_data_northi = cas_nation_api_northi.get_json()\n",
    "\n",
    "    cas_nat_data_new = [cas_nation_data_eng, cas_nation_data_scot, cas_nation_data_wales, cas_nation_data_northi] # combining the data\n",
    "\n",
    "    ### calling the death gender data ###\n",
    "\n",
    "    # defining the filters\n",
    "\n",
    "    death_filters = [\n",
    "        'areaType=Overview'\n",
    "    ]\n",
    "\n",
    "    sex_filter = [\n",
    "        'areaType=nation',\n",
    "        'areaName=England', # remember to highlight this\n",
    "    ]\n",
    "\n",
    "    # defining the structure\n",
    "\n",
    "    death_structure = {\n",
    "        \"date\": \"date\",\n",
    "        \"deaths\": \"newDailyNsoDeathsByDeathDate\",\n",
    "    }\n",
    "\n",
    "    sex_structure = {\n",
    "        \"date\": \"date\",\n",
    "        \"femaleCases\": \"femaleCases\",\n",
    "        \"maleCases\": \"maleCases\",\n",
    "    }\n",
    "\n",
    "\n",
    "    death_api = Cov19API(filters=death_filters, structure=death_structure)  # calling the API for the deaths data\n",
    "    death_data_new = death_api.get_json()\n",
    "\n",
    "    sex_api = Cov19API(filters=sex_filter, structure=sex_structure)     # calling the APi for the gender + agebands data\n",
    "    sex_data_new=sex_api.get_json()\n",
    "\n",
    "    return {'pcrcompdata' : pcr_comp_data_new, 'vaxoccdata' : sick_vax_data_new, 'casnatdata' : cas_nat_data_new, 'deathdata' : death_data_new, 'genderdata' : sex_data_new} # return data read from the API as a dictionary to make it easy to call the right data later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b4ef4b235c1485da4c65022cd55a1dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='info', description='Refresh Data', icon='download', style=ButtonStyle(), tooltip='Click r…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### button & API callback ###\n",
    "\n",
    "def api_button_callback(button):\n",
    "    \"\"\" Button callback - it must take the button as its parameter (unused in this case).\n",
    "    Accesses API, wrangles data, updates global variable df used for plotting. \"\"\"\n",
    "    # Get fresh data from the API. If you have time, include some error handling\n",
    "    # around this call.\n",
    "\n",
    "    try:\n",
    "        apidata=access_api()\n",
    "    except ConnectionError as ConnectionErr:\n",
    "        print(\"We could not connect wit the publicly hosted database because the internet connection broke off. Your last refreshed data is still available and has not been overwritten\")\n",
    "\n",
    "    # wrangle the data and overwrite the dataframe for plotting\n",
    "\n",
    "    # for pcr_comp\n",
    "    global pcr_comp_df\n",
    "    pcr_comp_df=pcr_comp_wrangle(apidata['pcrcompdata'])\n",
    "\n",
    "    # for vaxx occ\n",
    "\n",
    "    global sick_vax_df\n",
    "    sick_vax_df = vax_occ_wrangle(apidata['vaxoccdata'])\n",
    "\n",
    "    global cas_nat_df_d\n",
    "    cas_nat_df_d = cas_nation_wrangle(apidata['casnatdata'])\n",
    "\n",
    "    global death_df\n",
    "    death_df = death_gender_wrangle(apidata['deathdata'], apidata['genderdata'])\n",
    "\n",
    "\n",
    "    # the graph won't refresh until the user interacts with the widget.\n",
    "    # this function simulates the interaction, see Graph and Analysis below.\n",
    "    # you can omit this step in the first instance\n",
    "    refresh_graph()\n",
    "    # after all is done, you can switch the icon on the button to a \"check\" sign\n",
    "    # and optionally disable the button - it won't be needed again. You can use icons\n",
    "    # \"unlink\" or \"times\" and change the button text to \"Unavailable\" in case the \n",
    "    # api call fails.\n",
    "    apibutton.icon=\"check\"\n",
    "    apibutton.disabled=True   \n",
    "\n",
    "    \n",
    "\n",
    "apibutton=wdg.Button(\n",
    "    description='Refresh Data', # you may want to change this...\n",
    "    disabled=False,\n",
    "    button_style='info', # 'success', 'info', 'warning', 'danger' or ''\n",
    "    tooltip=\"Click ro refresh data\",\n",
    "    # FontAwesome names without the `fa-` prefix - try \"download\"\n",
    "    icon='download'\n",
    ")\n",
    "\n",
    "# remember to register your button callback function with the button\n",
    "apibutton.on_click(api_button_callback) # the name of your function inside these brackets\n",
    "\n",
    "display(apibutton)\n",
    "\n",
    "# run all cells before clicking on this button"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 📊Corona Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently, you find here four charts based on the most up to date data (use refresh to load fresh data from the corona API):\n",
    "\n",
    "- PCR Testing versus planned PCR Capacity \n",
    "- Vaccination Rates per Vaccine versus occupied MV (Ventilator) Beds and cummulative Admissions (available at different scales)\n",
    "- National Corona Cases per UK Nation (available at different timescales)\n",
    "- Daily overall corona deaths mapped on top of corona cases in England, shown by age group and gender (available at different timescales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔬PCR Testing compared to planned PCR testing Capacity\n",
    "\n",
    "Here we are comparing planned PCR testing capacity with acctually performed PCR tests across time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85abf93f213a4d00901c21eb6a291f83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SelectMultiple(description='Categories', index=(0, 1), options=('newPCR', 'plannedPCR'), rows=2, value=('newPC…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0fd1e93ffaa4a27aa63bfae8b9271f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### having seperate code boxed to plot charts individually? and provide descriptions? probably better\n",
    "\n",
    "\n",
    "\n",
    "### pcr_comp plotting ###\n",
    "pcr_cols=wdg.SelectMultiple(\n",
    "    options=['newPCR', 'plannedPCR'], # could add \"delta\" later\n",
    "    value=['newPCR', 'plannedPCR'], # initial value\n",
    "    rows=2, # rows of the selection box\n",
    "    description='Categories',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "\n",
    "def pcr_comp_graph(graphcolumns):\n",
    "    # our callback function.\n",
    "    ncols=len(graphcolumns)\n",
    "    if ncols>0:\n",
    "        pcr_comp_df.plot(title =\"Planned compared to new PCR Tests\", ylabel=\"PCR\", kind='line', y=list(graphcolumns)) # graphcolumns is a tuple - we need a list\n",
    "        plt.show() # important - graphs won't update properly if this is missing\n",
    "    else:\n",
    "        # if the user has not selected any column, print a message instead\n",
    "        print(\"Click to select data for graph\")\n",
    "        print(\"(CTRL-Click to select more than one category)\")\n",
    "    \n",
    "# keep calling age_graph(graphcolumns=value_of_agecols); capture output in widget output    \n",
    "\n",
    "\n",
    "####\n",
    "\n",
    "graph_pcr_comp=wdg.interactive_output(pcr_comp_graph, {'graphcolumns': pcr_cols})\n",
    "\n",
    "display(pcr_cols, graph_pcr_comp)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 💉Cummulative Vaccination Rates per Vaccine compared to daily occupied MV Beds and cummulative Admissions\n",
    "\n",
    "Here we can compare the cummulated vaccination rates for each vaccine to daily occupied Medical Ventilator (MV) beds and cummulative Admissons. Explore the data by selecting all or only select vaxcination rates and toggle between the MV beds data and the cummulative Admissions. You can also experiment with log scale and compare the results to linear scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b97566b444ef44488c4487c026c16cb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(SelectMultiple(description='Vaxcines', index=(0, 1, 2), options=('cumVax1', 'cumVax2', 'cumVax3…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d442909ae1ed47178f997aab6d502bf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## vax_occ plotting ###\n",
    "\n",
    "vaxcols=wdg.SelectMultiple(\n",
    "    options=['cumVax1', 'cumVax2', 'cumVax3'], \n",
    "    value=['cumVax1', 'cumVax2', \"cumVax3\"],\n",
    "    rows=3, \n",
    "    description='Vaxcines',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "occcols=wdg.RadioButtons(     # radio button for the yaxis select\n",
    "    options=['occMVBeds', \"cumAdmin\"], \n",
    "    #value=['occMVBeds', \"cumAdmin\" ],  \n",
    "    description='Severity Indicators',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "\n",
    "vax_occ_scale=wdg.RadioButtons(\n",
    "    options=['linear', 'log'],\n",
    "#    value='pineapple', # Defaults to 'pineapple'\n",
    "#    layout={'width': 'max-content'}, # If the items' names are long\n",
    "    description='Scale:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "controls=wdg.HBox([vaxcols, occcols, vax_occ_scale])\n",
    "\n",
    "def vax_occ_graph(graphcolumns, ycolumns, gscale):   # check here which values we should name / does it matter?\n",
    "    \n",
    "    ncols=len(graphcolumns)\n",
    "\n",
    "    if gscale=='linear':    # controlling for the liner/log scale\n",
    "        logscale=False\n",
    "    else:\n",
    "        logscale=True\n",
    "\n",
    "    if occcols.value == \"occMVBeds\":   # selecting for either the occupied beds or the cummulative Addmissions via yaxis state\n",
    "        yaxis_state = \"occMVBeds\"\n",
    "        yaxis_desc = \"MV Bed Occupancy\"\n",
    "    else:                                           # controlling for the secondary y axis\n",
    "        yaxis_state = \"cumAdmin\"\n",
    "        yaxis_desc = \"Cummulative Admissions\"\n",
    "\n",
    "\n",
    "    if ncols>0:\n",
    "        sick_vax_df.plot( y=list(graphcolumns), logy=logscale, use_index=True) \n",
    "        ax = sick_vax_df[yaxis_state].plot(secondary_y=True, title=\"Vaccination Rates compared to occupied MV Beds and Admissions\", ylabel=\"Cummulative Vaccinations\", logy=logscale, color='k')  # plotting a secondary y axis to plot data at different dimensions\n",
    "        ax.set_ylabel(yaxis_desc)\n",
    "        plt.show() \n",
    "    \n",
    "    else:\n",
    "        # if the user has not selected any column, print a message instead\n",
    "        print(\"Click to select data for graph\")\n",
    "        print(\"(CTRL-Click to select more than one category)\")\n",
    "    \n",
    "# keep calling age_graph(graphcolumns=value_of_agecols); capture output in widget output    \n",
    "graph_vax_occ=wdg.interactive_output(vax_occ_graph, {'graphcolumns': vaxcols, \"ycolumns\" : occcols, \"gscale\":vax_occ_scale})\n",
    "#output2=wdg.interactive_output(age_graph, {'graphcolumns': occcols})\n",
    "\n",
    "display(controls, graph_vax_occ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🏛Corona Cases per UK Nation\n",
    "\n",
    "In this graph, we take a look at the number of corona cases for each nation in the United Kingdom (🏴󠁧󠁢󠁥󠁮󠁧󠁿🏴󠁧󠁢󠁳󠁣󠁴󠁿🏴󠁧󠁢󠁷󠁬󠁳󠁿🇬🇧). You are able to switch between monthly and daily scales and also have sliders for each available to \"zoom in\" or \"zoom out\" by making the time horizon more or less granular. Just make sure to use the right slider for the timescale that you selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cb41e2a4e2949839523385fee068dbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(SelectMultiple(description='Nations', index=(0, 1, 2, 3), options=('England', 'Scotland', 'Wale…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b1dd7e8be0b49178320a022fcc04957",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf372b36f7b844c09a426f4145d04d86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntSlider(value=3, continuous_update=False, description='Months:', max=12, min=1), IntSlider(va…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "natcols=wdg.SelectMultiple(\n",
    "    options=['England', 'Scotland', 'Wales', 'Northern Ireland'], # options available\n",
    "    value=['England', 'Scotland', 'Wales', 'Northern Ireland'], # initial value\n",
    "    rows=4, # rows of the selection box\n",
    "    description='Nations',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "timescale=wdg.RadioButtons(\n",
    "    options=['Daily', 'Monthly'],\n",
    "    description='Scale:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "timeslider=wdg.IntSlider(\n",
    "    value=3,\n",
    "    min=1,\n",
    "    max=12,\n",
    "    step=1,\n",
    "    description='Months:',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d'\n",
    ")\n",
    "\n",
    "timeslider2=wdg.IntSlider(\n",
    "    value=1,\n",
    "    min=1,\n",
    "    max=31,\n",
    "    step=1,\n",
    "    description='Days:',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d'\n",
    ")\n",
    "\n",
    "controls=wdg.HBox([natcols, timescale])\n",
    "sliderbox=wdg.HBox([timeslider, timeslider2])\n",
    "\n",
    "\n",
    "\n",
    "def cas_nat_graph(nationcolumns, tscale, timevalue, timevalue2):\n",
    "\n",
    "    # our callback function.\n",
    "    ncols=len(nationcolumns)\n",
    "    \n",
    "    m_value = str(timeslider.value) + \"m\"\n",
    "    d_value = str(timeslider2.value) + \"d\"\n",
    "\n",
    "    if ncols>0:\n",
    "\n",
    "        if  tscale=='Daily':\n",
    "            cas_nat_df_dd = cas_nat_df_d.resample(d_value).sum() # had to use the dd naming to have a new variable -> could be cleaner\n",
    "            cas_nat_df_dd.plot( y=list(nationcolumns), title=\"Corona Cases per UK Nation\", ylabel=\"Cases\")\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        else: \n",
    "            cas_nat_df_m = cas_nat_df_d.resample(m_value).sum()\n",
    "            cas_nat_df_m.plot( y=list(nationcolumns), title=\"Corona Cases per UK Nation\", ylabel=\"Cases\",kind='bar', use_index=True)\n",
    "            plt.show()\n",
    "            slider_dis = False\n",
    "            print(slider_dis)\n",
    "            return slider_dis\n",
    "\n",
    "    else:\n",
    "        \n",
    "        print(\"Click to select data for graph\")\n",
    "        print(\"(CTRL-Click to select more than one category)\")\n",
    "    \n",
    "  \n",
    "graph_cas_nat=wdg.interactive_output(cas_nat_graph, {'nationcolumns': natcols, \"tscale\": timescale, \"timevalue\": timeslider, \"timevalue2\":timeslider2}) # clean up slider names + order\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "display(controls, graph_cas_nat, sliderbox)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🗞Daily Corona Deaths (UK-wide) compared with cummulative Corona Cases in England\n",
    "\n",
    "Here we look at UK-wide corona deaths and compate them demographic corona case data from England. Daily Corona deaths are fixed to a one-month intervall timescale in order to preserve granularity of spikes in the data. But you can experiment with different timehoizons for the corona cases by using the slider. And you can compare different age bands for both female and male cases or select all for a total overview. \n",
    "\n",
    "The cummulative case data is now forward-filling for the changing timescales, meaning that it handles the averaging over a too far extended timeperiod problem, where it would appear as if the cummulative data would decrease for the last time intervall (which is of course logically inconsistent)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d05ffc4c83a4e928a92f6a9fef65234",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(SelectMultiple(description='Female Age Bands', index=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6671a1dcd6b4161849548385194163b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "female_age_cols=wdg.SelectMultiple(\n",
    "    options=[\"F_0_to_4\", \"F_5_to_9\", \"F_10_to_14\", \"F_15_to_19\", \"F_20_to_24\", \"F_25_to_29\", \"F_30_to_34\", \"F_35_to_39\", \"F_40_to_44\", \"F_45_to_49\", \"F_50_to_54\", \"F_55_to_59\", \"F_60_to_64\", \"F_65_to_69\", \"F_70_to_74\", \"F_75_to_79\", \"F_80_to_84\", \"F_85_to_89\", \"F_90_to_94\", \"F_90+\"],\n",
    "    value=[\"F_0_to_4\", \"F_5_to_9\", \"F_10_to_14\", \"F_15_to_19\", \"F_20_to_24\", \"F_25_to_29\", \"F_30_to_34\", \"F_35_to_39\", \"F_40_to_44\", \"F_45_to_49\", \"F_50_to_54\", \"F_55_to_59\", \"F_60_to_64\", \"F_65_to_69\", \"F_70_to_74\", \"F_75_to_79\", \"F_80_to_84\", \"F_85_to_89\", \"F_90_to_94\", \"F_90+\"],\n",
    "    rows= 20, # rows of the selection box\n",
    "    description='Female Age Bands',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "male_age_cols=wdg.SelectMultiple(\n",
    "    options=[\"M_0_to_4\", \"M_5_to_9\", \"M_10_to_14\", \"M_15_to_19\", \"M_20_to_24\", \"M_25_to_29\", \"M_30_to_34\", \"M_35_to_39\", \"M_40_to_44\", \"M_45_to_49\", \"M_50_to_54\", \"M_55_to_59\", \"M_60_to_64\", \"M_65_to_69\", \"M_70_to_74\", \"M_75_to_79\", \"M_80_to_84\", \"M_85_to_89\", \"M_90_to_94\", \"M_90+\"],\n",
    "    value=[],\n",
    "    rows= 20, # rows of the selection box\n",
    "    description='Male Age Bands',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "timeslider3=wdg.IntSlider(\n",
    "    value=9,\n",
    "    min=1,\n",
    "    max=12,\n",
    "    step=1,\n",
    "    description='Monthly Intervall',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d'\n",
    ")\n",
    "\n",
    "controls = wdg.HBox([female_age_cols, male_age_cols, timeslider3])\n",
    "\n",
    "def death_gender_graph(femagecols, menagecols, timevalue):\n",
    "\n",
    "    # our callback function.\n",
    "    ncols=len(femagecols)\n",
    "    m_value = str(timeslider3.value) + \"m\"\n",
    "\n",
    "\n",
    "    if ncols>0:\n",
    "        death_df_mm= death_df.resample(m_value).ffill()         # after a long time of trying .sum() I switched this to .ffill(). This is because with sum you average over missing values and this makes the cummulative chart appear to have a negative slope for the last time intervall\n",
    "        death_df_m=death_df.resample(\"1m\").sum()       # explain this in the header -> we are fixing this at a one month intervall to have the right resolution for deaths\n",
    "        death_df_mm.plot(y=list(femagecols + menagecols), title=\"Daily Corona Deaths (UK-wide) compared with cummulative Corona Cases in England\" ,ylabel=\"Cummulative Cases\",kind=\"area\", logy = False, use_index=True, figsize=(20,10)) # graphcolumns is a tuple - we need a list\n",
    "        #death_df_mm.title(\"Daily Corona Deaths (UK-wide) compared with cummulative Corona Cases in England\")\n",
    "        ax = death_df_m[\"DailyDeaths\"].plot(secondary_y=True, color='k')    # check here if you want daily or resampled data\n",
    "        ax.set_ylabel('Daily Deaths')\n",
    "        plt.show()\n",
    "\n",
    "    else:\n",
    "        \n",
    "        print(\"Click to select data for graph\")\n",
    "        print(\"(CTRL-Click to select more than one category)\")\n",
    "    \n",
    "  \n",
    "graph_death_gender=wdg.interactive_output(death_gender_graph, {'femagecols': female_age_cols, \"menagecols\" : male_age_cols, \"timevalue\": timeslider3}) # clean up slider names + order\n",
    "\n",
    "display(controls, graph_death_gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### refreshing the charts ###\n",
    "\n",
    "def refresh_graph():\n",
    "    \"\"\" We change the value of the widget in order to force a redraw of the graph;\n",
    "    this is useful when the data have been updated. This is a bit of a gimmick; it\n",
    "    needs to be customised for one of your widgets. \"\"\"\n",
    "\n",
    "    # trying a loop over all the charts here\n",
    "    chartcontr_lst = [pcr_cols, vaxcols, female_age_cols, natcols] # loop over one control widget for each graph\n",
    "\n",
    "    for chart in chartcontr_lst:    # go through the steps of changing / unchanging an option for each graph\n",
    "\n",
    "        current=chart.value\n",
    "        if current==chart.options[0]:\n",
    "            other=(chart.options[1],)       # had to implement a fix here. The widget would not take a string as an input, ony a tuple containing the string (mirrored the format of print(chart.value))\n",
    "        else:\n",
    "            other=(chart.options[0],)       # see above comment for format\n",
    "        chart.value=other # forces the redraw\n",
    "        chart.value=current # changing it back\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Any feedback?\n",
    "\n",
    "📧 jan@fount.io\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Copyright JanFrommann,2022 (jan@fount.io / ec22301@qmul.ac.uk).** *Based on UK Government [data](https://coronavirus.data.gov.uk/) published by [Public Health England](https://www.gov.uk/government/organisations/public-health-england).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[DIY Covid-19 Dashboard Kit](https://github.com/fsmeraldi/diy-covid19dash) (C) Fabrizio Smeraldi, 2020 ([f.smeraldi@qmul.ac.uk](mailto:f.smeraldi@qmul.ac.uk) - [web](http://www.eecs.qmul.ac.uk/~fabri/)). All rights reserved."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "c6609c9133a6db690f016f49050ce97a9a809177a34a79c19b62b14f5faf7a07"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
